{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quick Start\n",
    "To run this notebook you just need to have [pipenv](https://github.com/pypa/pipenv) installed.\n",
    "Then run these 3 commands:\n",
    "- first install the dependencies with: `pipenv install`\n",
    "- launch the virtual env: `pipenv shell`\n",
    "- finally start jupyter and open the notebook: `jupyter-lab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel \n",
    "\n",
    "from surprise import NormalPredictor, SVD, KNNBasic, NMF\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Recommender systems goal is to push *relevant* items to a given user. Understanding and modelling the user's preferences is required to reach this goal. In this project you will learn how to model the user's preferences with the [Surprise library](http://surpriselib.com/) to build different recommender systems. The first one will be a pure *collaborative filtering* approach, and the second one will rely on item attributes in a *content-based* way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data\n",
    "We use here the [MovieLens dataset](https://grouplens.org/datasets/movielens/). It contains 25 millions of users ratings. the data are in the `./data/raw` folder. We could load directly the .csv file with [a built-in Surprise function](https://github.com/NicolasHug/Surprise/blob/ef3ed6e98304dbf8d033c8eee741294b05b5ba07/surprise/dataset.py#L105), but it's more convenient to load it through a Pandas dataframe for later flexibility purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATINGS_DATA_FILE = './data/raw/ratings.csv'\n",
    "MOVIES_DATA_FILE = './data/raw/movies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw csv into a data_frame\n",
    "df_ratings = pd.read_csv(RATINGS_DATA_FILE)\n",
    "\n",
    "# drop the timestamp column since we dont need it now\n",
    "df_ratings = df_ratings.drop(columns=\"timestamp\")\n",
    "\n",
    "# movies dataframe\n",
    "df_movies = pd.read_csv(MOVIES_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000095"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check we have 25M users' ratings\n",
    "df_ratings.userId.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(df, number):\n",
    "    \"\"\"\n",
    "        just get a subset of a large dataset for debug purpose\n",
    "    \"\"\"\n",
    "    rids = np.arange(df.shape[0])\n",
    "    np.random.shuffle(rids)\n",
    "    df_subset = df.iloc[rids[:number], :].copy()\n",
    "    return df_subset\n",
    "df_ratings_100k = get_subset(df_ratings, 100000)\n",
    "df_movies_100 = get_subset(df_movies, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise reader\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Finally load all ratings\n",
    "ratings = Dataset.load_from_df(df_ratings_10k, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collaborative Filtering\n",
    "We can test first any of the [Surprise algorithms](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algos = [SVD(), NMF(), KNNBasic()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0408\n",
      "RMSE: 1.0949\n",
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "RMSE: 1.0608\n",
      "RMSE: 1.0489\n",
      "RMSE: 1.1087\n",
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "RMSE: 1.0745\n",
      "RMSE: 1.0303\n",
      "RMSE: 1.0855\n",
      "Computing the msd similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "RMSE: 1.0559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_rmse(algo, testset):\n",
    "        predictions = algo.test(testset)\n",
    "        accuracy.rmse(predictions, verbose=True)\n",
    "        \n",
    "for trainset, testset in tqdm(kf.split(ratings)): \n",
    "    \"\"\"\n",
    "        get an evaluation with cross-validation for different algorithms\n",
    "    \"\"\"  \n",
    "    for algo in algos:\n",
    "        algo.fit(trainset)\n",
    "        get_rmse(algo, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO from now**: \n",
    "- test different similarity measures\n",
    "- test different computation methods (ALS vs SGD) and conclude\n",
    "- test with different parameters\n",
    "- tune to find the best parameters\n",
    "- visualization & interpretation of results\n",
    "- these first results can serve as a baseline to improve next\n",
    "- personalize candidate generation by selecting the most popular items  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Content-based Filtering\n",
    "Here we will rely directly on items attributes. First we have to describe a user profile with an attributes vector. Then we will use these vectors to generate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162126</td>\n",
       "      <td>Autobiography of a Princess (1975)</td>\n",
       "      <td>(no genres listed)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194666</td>\n",
       "      <td>Roads in February (2018)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157679</td>\n",
       "      <td>Alley Cats Strike (2000)</td>\n",
       "      <td>Children|Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169196</td>\n",
       "      <td>Once Upon a Time Veronica (2012)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191777</td>\n",
       "      <td>Revenge: A Love Story (2010)</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>150870</td>\n",
       "      <td>Tekken: Blood Vengeance (2011)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>122280</td>\n",
       "      <td>Sabretooth (2002)</td>\n",
       "      <td>Action|Adventure|Horror|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>186257</td>\n",
       "      <td>Criminal Talent (1988)</td>\n",
       "      <td>Comedy|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>187309</td>\n",
       "      <td>The Week Of (2018)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>159976</td>\n",
       "      <td>Pelé: Birth of a Legend (2016)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId                               title  \\\n",
       "0    162126  Autobiography of a Princess (1975)   \n",
       "1    194666            Roads in February (2018)   \n",
       "2    157679            Alley Cats Strike (2000)   \n",
       "3    169196    Once Upon a Time Veronica (2012)   \n",
       "4    191777        Revenge: A Love Story (2010)   \n",
       "..      ...                                 ...   \n",
       "95   150870      Tekken: Blood Vengeance (2011)   \n",
       "96   122280                   Sabretooth (2002)   \n",
       "97   186257              Criminal Talent (1988)   \n",
       "98   187309                  The Week Of (2018)   \n",
       "99   159976      Pelé: Birth of a Legend (2016)   \n",
       "\n",
       "                                     genres  \n",
       "0                        (no genres listed)  \n",
       "1                                     Drama  \n",
       "2                     Children|Comedy|Drama  \n",
       "3                                     Drama  \n",
       "4                                  Thriller  \n",
       "..                                      ...  \n",
       "95                         Action|Animation  \n",
       "96  Action|Adventure|Horror|Sci-Fi|Thriller  \n",
       "97                       Comedy|Crime|Drama  \n",
       "98                                   Comedy  \n",
       "99                                    Drama  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing similarities requires too much ressources on the whole dataset, so we take the subset with 100 items\n",
    "df_movies_100 = df_movies_100.reset_index(drop=True)\n",
    "df_movies_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute a TFIDF on the titles of the movies\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df_movies_100['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get cosine similarities: this takes a lot of time on the real dataset\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we generate in 'results' the most similar movies for each movie: we put a pair (score, movie_id)\n",
    "results = {}\n",
    "for idx, row in df_movies_100.iterrows():\n",
    "    similar_indices = cosine_similarities[idx].argsort()[:-100:-1] \n",
    "    similar_items = [(cosine_similarities[idx][i], df_movies_100['movieId'].loc[[i]].tolist()[0]) for i in similar_indices] \n",
    "    results[idx] = similar_items[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a 'movieId' into its corresponding movie title\n",
    "def item(id):  \n",
    "    return df_movies_100.loc[df_movies_100['movieId'] == id]['title'].tolist()[0].split(' - ')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a 'movieId' into the index id\n",
    "def get_idx(id):\n",
    "    return df_movies_100[df_movies_100['movieId'] == id].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we put everything together here:\n",
    "def recommend(item_id, num):\n",
    "    print(\"Recommending \" + str(num) + \" products similar to \" + item(item_id) + \"...\")   \n",
    "    print(\"-------\")    \n",
    "    recs = results[get_idx(item_id)][:num]   \n",
    "    for rec in recs: \n",
    "        print(\"\\tRecommended: \" + item(rec[1]) + \" (score:\" +      str(rec[0]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a user wants the 10 most 'similar' (from a CBF point of view) movies from the movie 'Alley Cats Strike':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending 10 products similar to Alley Cats Strike (2000)...\n",
      "-------\n",
      "\tRecommended: Ringu 0: Bâsudei (2000) (score:0.10424703060511913)\n",
      "\tRecommended: 6th Day, The (2000) (score:0.10424703060511913)\n",
      "\tRecommended: Room 205 of Fear (2011) (score:0.0)\n",
      "\tRecommended: Legend (2015) (score:0.0)\n",
      "\tRecommended: Hardcore (2001) (score:0.0)\n",
      "\tRecommended: The Huntress: Rune of the Dead (2019) (score:0.0)\n",
      "\tRecommended: House of Dracula (1945) (score:0.0)\n",
      "\tRecommended: Schramm (1993) (score:0.0)\n",
      "\tRecommended: The Coed and the Zombie Stoner (2014) (score:0.0)\n",
      "\tRecommended: Honor Among Lovers (1931) (score:0.0)\n"
     ]
    }
   ],
   "source": [
    "recommend(item_id=157679, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "- what are the advantages of CBF over CF ? Discuss results...\n",
    "- Surprise does not support content-based information. The goal here is to implement a content-based algorithm in to Surprise\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
